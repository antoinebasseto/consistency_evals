import ast
import json
import os
import re
from pathlib import Path
from typing import Any, Dict, List, Tuple

import pandas as pd
from tqdm import tqdm

from dataset_handlers.dataset_handler import DatasetHandler
from plots import plot_answer_distribution, plot_text_clusters


class NEJMHandler(DatasetHandler):
    SYSTEM_PROMPT = {
        "recommendation": "You are a helpful assistant.",
        "hypothesis": "You are a helpful assistant.",
    }
    MESSAGE_PROMPT_START = {
        "recommendation": """
You are a highly knowledgeable and helpful clinical assistant specializing in providing detailed and accurate evaluations of diagnostic hypotheses. Your primary role is to assist clinicians by thoroughly examining and interpreting clinical cases.

You will be provided with a case description and a list of diagnostic hypotheses for this case, generated by the clinician you are assisting.

Your task is to:

    1. Reflect upon the case description, evaluating each hypothesis independently to see if it presents a likely diagnosis for the given case. Be meticulous in evaluating every piece of evidence available in the case description. Ensure each piece of evidence is assessed correctly, offering a balanced view of its implications.
    2. Provide a lead diagnosis from the list of hypotheses provided. This diagnosis should be the most probable based on the evidence presented in the case description.
    3. Provide a rationale explaining why the lead diagnosis you chose is the most probable, citing the case description to support your claims.
    4. Your explanations should be detailed and understandable, intended to assist the clinician in making an informed decision.
    5. Quote direct passages from the case description to support your claims.

Here are the detailed guidelines for completing your task:
    - Thorough Analysis: Take your time to think through each piece of evidence step-by-step. Consider all aspects of the case description and the diagnostic hypotheses.
    - Direct Citations: Any time you use information from the case description, annotate the claim with direct, continuous passages from the text. If multiple passages are needed, cite each one separately WITHOUT using ellipses. Make sure you only cite passages that can be found in the case description! Citations will be collected in the "citations" list, and references to that list made in the "rationale" text, by using square brackets containing the index number of the corresponding citation, e.g. [1].
    - Detailed Explanations: Provide comprehensive explanations that elucidate why the evidence supports the chosen lead diagnosis. Use clear, clinical reasoning to explain your thought process.

Remember, the goal is to recommend the correct lead diagnosis. Your thoroughness and attention to detail are crucial for ensuring the clinician has all the necessary information to make an informed decision.

Take your time to do the task correctly and think things through step by step.

Answer using a JSON format.
""".strip(),
        "hypothesis": """
You are a highly knowledgeable and helpful clinical assistant specializing in providing detailed and accurate evaluations of diagnostic hypotheses. Your primary role is to assist clinicians by thoroughly examining and interpreting clinical cases.

You will be provided with a case description and multiple diagnostic hypotheses for this case, generated by the clinician you are assisting.

Your task is to:

    1. Provide both evidence supporting and contradicting the given hypothesis.
    2. Be meticulous in evaluating every piece of evidence available in the case description.
    3. Ensure each piece of evidence is assessed correctly, offering a balanced view of its implications.
    4. For every claim you make, provide a clear explanation as to why it supports or refutes the hypothesis. Your explanations should be detailed and understandable, intended to assist the clinician in making an informed decision.
    5. Quote direct passages from the case description to support your claims.

Guidelines for completing your task:

    - Direct Citations: Any time you use information from the case description, annotate the claim with direct, continuous passages from the text. If multiple passages are needed, cite each one separately WITHOUT using ellipses. Make sure you only cite passages that can be found in the case description!
    - Thorough Analysis: Take your time to think through each piece of evidence step-by-step. Consider all aspects of the case description and the diagnostic hypothesis.
    - Detailed Explanations: Provide comprehensive explanations that elucidate why the evidence supports or contradicts the hypothesis. Use clear, clinical reasoning to explain your thought process.
    - Balanced Evaluation: Ensure that your analysis is balanced and impartial, presenting a fair evaluation of all evidence.

Remember, the goal is to assist the clinician by providing a clear, well-reasoned analysis of the evidence for and against the diagnostic hypothesis. Your thoroughness and attention to detail are crucial for ensuring the clinician has all the necessary information to make an informed decision.

Take your time to do the task correctly and think things through step by step.

Answer using a JSON format.
""".strip(),
    }

    def __init__(self, engine: str, experiment: str, ai_type: str) -> None:
        super().__init__("nejm", engine, experiment, ai_type)

    def gen_batch_inputs(
        self, k_shot: int = 0, max_options_lists: int = -1, temperature: float = 0.0
    ) -> None:
        if k_shot != 0:
            raise NotImplementedError("k-shot learning is not supported for NEJM")

        for file_name in tqdm(os.listdir(self.get_raw_data_dir())):
            batch_inputs = []
            file_path = os.path.join(self.get_raw_data_dir(), file_name)
            with open(file_path, "r") as file:
                case_data = json.load(file)
                case_name = file_name.removesuffix(".json")
                case_description = case_data["description"]
                original_options = case_data["hypotheses"]

                options_lists = self._gen_experiment_options_lists(
                    original_options, max_options_lists
                )

                for options in options_lists:
                    prompt = self._gen_prompt(case_description, options)
                    json_schema = (
                        self._gen_json_schema_for_recommendation_driven()
                        if self.ai_type == "recommendation"
                        else self._gen_json_schema_for_hypothesis_driven(options)
                    )
                    batch_input_line = self._gen_batch_input_line(
                        f"{case_name}_{options}",
                        prompt,
                        temperature=temperature,
                        force_json=True,
                        json_schema=json_schema,
                    )
                    batch_inputs.append(batch_input_line)

            with open(
                os.path.join(
                    self.get_batch_inputs_dir(),
                    f"input_{case_name}_temp_{temperature}.jsonl",
                ),
                "w",
            ) as file:
                for entry in batch_inputs:
                    json_line = json.dumps(entry)
                    file.write(json_line + "\n")

    def parse_batch_output_line(self, line: str) -> List[Dict[str, Any]]:
        raw_output = json.loads(line)
        options = ast.literal_eval(raw_output["custom_id"].split("_")[-1])
        raw_answer = raw_output["response"]["body"]["choices"][0]["message"]["content"]
        json_answer = json.loads(raw_answer)

        results = []

        if self.ai_type == "recommendation":
            json_answer["lead_diagnosis"] = re.sub(r"^[A-Z]\. ", '', json_answer["lead_diagnosis"])
            result = {
                "options": options,
                "answer": json_answer["lead_diagnosis"],
                "rationale": json_answer["rationale"],
                "citations": json_answer["citations"],
            }
            results.append(result)

        elif self.ai_type == "hypothesis":
            for option in options:
                for evidence_type in ["evidence_for", "evidence_against"]:
                    for claim_and_citations in json_answer[option][evidence_type]:
                        result = {
                            "options": options,
                            "option": option,
                            "evidence_type": evidence_type,
                            "claim": claim_and_citations["claim"],
                            "citations": claim_and_citations["citations"],
                        }
                        results.append(result)

        return results

    def gen_results(self) -> None:
        for file_name in tqdm(os.listdir(self.get_parsed_batch_outputs_dir())):
            file_path = os.path.join(self.get_parsed_batch_outputs_dir(), file_name)
            df = pd.read_csv(file_path)

            if self.ai_type == "recommendation":
                self._gen_results_for_recommendation_driven(df, file_name)

            if self.ai_type == "hypothesis":
                self._gen_results_for_hypothesis_driven(df, file_name)

    def _gen_results_for_recommendation_driven(
        self, df: pd.DataFrame, file_name: str
    ) -> None:
        results_file_name = file_name.removesuffix(".csv")

        plot_answer_distribution(
            df,
            ast.literal_eval(df["options"].iloc[0]),
            "answer",
            self.get_results_dir(),
            f"{results_file_name}_answer_distribution",
        )

    def _gen_results_for_hypothesis_driven(
        self, df: pd.DataFrame, file_name: str
    ) -> None:
        df["answer_id"] = df["options"].factorize()[0].astype(str)
        results_file_name = file_name.removesuffix(".csv")

        for option in df['option'].unique():
            evidence_for = df[(df["option"] == option) & (df["evidence_type"] == "evidence_for")].copy()
            evidence_against = df[(df["option"] == option) & (df["evidence_type"] == "evidence_against")].copy()
            for evidence in [evidence_for, evidence_against]:
                plot_text_clusters(
                    evidence,
                    "claim",
                    "answer_id",
                    self.get_results_dir(),
                    f"{results_file_name}_{option}_{evidence["evidence_type"].iloc[0]}",
                )

    def _gen_json_schema_for_recommendation_driven(self) -> object:
        return {
            "name": "get_diagnosis",
            "description": "Provide a diagnosis for the given case.",
            "schema": {
                "type": "object",
                "properties": {
                    "rationale": {
                        "type": "string",
                        "description": "Your rationale for the diagnosis you provided, citing the case description to support your claims.",
                    },
                    "citations": {
                        "type": "array",
                        "description": "Direct citation from the case description that back up the rationale",
                        "items": {"type": "string"},
                    },
                    "lead_diagnosis": {
                        "type": "string",
                        "description": "The diagnosis you believe is most likely based on the evidence presented.",
                    },
                },
                "required": ["lead_diagnosis", "citations", "rationale"],
                "additionalProperties": False,
            },
            "strict": True,
        }

    def _gen_json_schema_for_hypothesis_driven(
        self, options: Tuple[str, ...]
    ) -> object:
        schema = {
            "name": "get_evidence_for_and_against",
            "description": "Provide evidence supporting and contradicting the given hypothesis.",
            "schema": {
                "type": "object",
                "properties": {},
                "required": [option for option in options],
                "additionalProperties": False,
            },
            "strict": True,
        }
        for option in options:
            schema["schema"]["properties"][option] = {
                "type": "object",
                "properties": {
                    "evidence_for": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "claim": {
                                    "type": "string",
                                    "description": "A statement presenting evidence supporting the hypothesis, and explaining why.",
                                },
                                "citations": {
                                    "type": "array",
                                    "description": "Direct citation from the case description that back up the claim",
                                    "items": {"type": "string"},
                                },
                            },
                            "required": ["claim", "citations"],
                            "additionalProperties": False,
                        },
                    },
                    "evidence_against": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "claim": {
                                    "type": "string",
                                    "description": "A statement presenting evidence refuting the hypothesis, and explaining why.",
                                },
                                "citations": {
                                    "type": "array",
                                    "description": "Direct citation from the case description that back up the claim",
                                    "items": {"type": "string"},
                                },
                            },
                            "required": ["claim", "citations"],
                            "additionalProperties": False,
                        },
                    },
                },
                "additionalProperties": False,
                "required": ["evidence_for", "evidence_against"],
            }
        return schema
